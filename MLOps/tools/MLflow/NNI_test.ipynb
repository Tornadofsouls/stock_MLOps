{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\py380\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "'''\n",
    "training_data = pd.read_csv('C:/Users/is_li/Desktop/paper/github/stock on MLOps/MLOps/tools/DVC/example/data/train.csv',\n",
    "index_col= [0,1],header=[0,1])\n",
    "valid_data = pd.read_csv('C:/Users/is_li/Desktop/paper/github/stock on MLOps/MLOps/tools/DVC/example/data/valid.csv',\n",
    "index_col= [0,1],header=[0,1])\n",
    "test_data = pd.read_csv('C:/Users/is_li/Desktop/paper/github/stock on MLOps/MLOps/tools/DVC/example/data/test.csv',\n",
    "index_col= [0,1],header=[0,1])\n",
    "'''\n",
    "df_data  = pd.read_csv('C:/Users/is_li/Desktop/paper/github/stock on MLOps/MLOps/tools/DVC/example/data/dataset.csv',\n",
    "index_col= [0,1],header=[0,1])\n",
    "df_data = df_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建两个列表，用来存储数据的特征和标签\n",
    "data_feat, data_target = [],[]\n",
    "\n",
    "# 设每条数据序列有20组数据\n",
    "seq = 10\n",
    "feature_num = 10\n",
    "\n",
    "for index in range(len(df_data) - seq):\n",
    "    # 构建特征集\n",
    "    data_feat.append(df_data['feature'].iloc[:,range(feature_num)][index: index + seq].values)\n",
    "    # 构建target集\n",
    "    data_target.append(df_data['label'][index:index + seq])\n",
    "\n",
    "# 将特征集和标签集整理成numpy数组\n",
    "data_feat = np.array(data_feat)\n",
    "data_target = np.array(data_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n",
      "5489\n"
     ]
    }
   ],
   "source": [
    "# 这里按照8:2的比例划分训练集和测试集\n",
    "test_set_size = int(np.round(0.1*df_data.shape[0]))  # np.round(1)是四舍五入，\n",
    "train_size = data_feat.shape[0] - (test_set_size) \n",
    "print(test_set_size)  # 输出测试集大小\n",
    "print(train_size)     # 输出训练集大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape =  torch.Size([5489, 10, 10])\n",
      "y_train.shape =  torch.Size([5489, 10, 1])\n",
      "x_test.shape =  torch.Size([611, 10, 10])\n",
      "y_test.shape =  torch.Size([611, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 这里第一个维度自动确定，我们认为其为batch_size，因为在LSTM类的定义中，设置了batch_first=True\n",
    "trainX = torch.from_numpy(data_feat[:train_size].reshape(-1,seq,feature_num)).type(torch.Tensor)   \n",
    "testX  = torch.from_numpy(data_feat[train_size:].reshape(-1,seq,feature_num)).type(torch.Tensor)\n",
    "trainY = torch.from_numpy(data_target[:train_size].reshape(-1,seq,1)).type(torch.Tensor)\n",
    "testY  = torch.from_numpy(data_target[train_size:].reshape(-1,seq,1)).type(torch.Tensor)\n",
    "print('x_train.shape = ',trainX.shape)\n",
    "print('y_train.shape = ',trainY.shape)\n",
    "print('x_test.shape = ',testX.shape)\n",
    "print('y_test.shape = ',testY.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=5\n",
    "train = torch.utils.data.TensorDataset(trainX,trainY)\n",
    "test = torch.utils.data.TensorDataset(testX,testY)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_dim = feature_num    # 数据的特征数\n",
    "hidden_dim = 2    # 隐藏层的神经元个数\n",
    "num_layers = 2     # LSTM的层数\n",
    "output_dim = 1     # 预测值的特征数\n",
    "                   #（这是预测股票价格，所以这里特征数是1，如果预测一个单词，那么这里是one-hot向量的编码长度）\n",
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size=1, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, _x):\n",
    "        x, _ = self.lstm(_x)  # _x is input, size (seq_len, batch, input_size)\n",
    "        s, b, h = x.shape  # x is output, size (seq_len, batch, hidden_size)\n",
    "        x = x.view(s * b, h)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(s, b, -1)  # 把形状改回来\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 设置MLflow追踪URI\n",
    "mlflow.set_tracking_uri(\"file:/path/to/mlflow\")\n",
    "\n",
    "# 设置实验名称\n",
    "mlflow.set_experiment(\"stock-price-prediction\")\n",
    "\n",
    "# 定义数据集类\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# 定义LSTM模型类\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_len, batch, input_size)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 定义训练函数\n",
    "def train_model(model, train_loader, test_loader, loss_func, optimizer, device, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        # 训练模式\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for i, (feat, target) in enumerate(train_loader):\n",
    "            feat, target = feat.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(feat)\n",
    "            loss = loss_func(pred, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # 测试模式\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for feat, target in test_loader:\n",
    "                feat, target = feat.to(device), target.to(device)\n",
    "                pred = model(feat)\n",
    "                loss = loss_func(pred, target)\n",
    "                test_loss += loss.item()\n",
    "            test_loss /= len(test_loader)\n",
    "\n",
    "        # 记录日志\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, epoch)\n",
    "        mlflow.log_metric(\"test_loss\", test_loss, epoch)\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}\")\n",
    "\n",
    "# 读取数据集\n",
    "df_data = pd.read_csv('C:/Users/is_li/Desktop/paper/github/stock on MLOps/MLOps/tools/DVC/example/data/dataset.csv', index_col=[0,1], header=[0,1])\n",
    "df_data = df_data.fillna(0)\n",
    "\n",
    "# 特征编码\n",
    "label_encoder = LabelEncoder()\n",
    "df_data[('feature', 'stock')] = label_encoder.fit_transform(df_data[('feature', 'stock')])\n",
    "\n",
    "# 构建数据集\n",
    "data = []\n",
    "seq_len = 10\n",
    "for i in range(len(df_data)-seq_len):\n",
    "    feat = df_data[('feature', slice(None))].iloc[i:i+seq_len].values\n",
    "    target = df_data['label'].iloc[i+seq_len]\n",
    "    data.append((feat, target))\n",
    "\n",
    "train_size = int(len(data)*0.8)\n",
    "train_set = StockDataset(data[:train_size])\n",
    "test_set = StockDataset(data[train_size:])\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Start an MLflow experiment\n",
    "mlflow.set_experiment(\"Model Training\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader, 0):\n",
    "        # 将数据移动到设备上\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计损失\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 返回平均损失\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloader, 0):\n",
    "            # 将数据移动到设备上\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 统计损失\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # 统计正确率\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # 返回平均损失和准确率\n",
    "    return running_loss / len(dataloader), correct / total\n",
    "\n",
    "\n",
    "# Log the parameters and metrics for each run\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"lr\", 0.01)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"dropout\", 0.2)\n",
    "    \n",
    "    model = train_model(lr=0.01, batch_size=32, dropout=0.2)\n",
    "    loss, accuracy = evaluate_model(model)\n",
    "    \n",
    "    mlflow.log_metric(\"loss\", loss)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # Save the model as an artifact\n",
    "    mlflow.pytorch.log_model(model, \"models\")\n",
    "\n",
    "num_epochs = 50\n",
    "loss_function = nn.MSELoss()  # 损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # 优化器\n",
    "\n",
    "# 定义 MLflow 参数\n",
    "experiment_name = \"stock-price-prediction\"\n",
    "run_name = \"LSTM\"\n",
    "params = {\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": 0.1\n",
    "}\n",
    "\n",
    "# 启动 MLflow 实验并记录参数\n",
    "mlflow.set_experiment(experiment_name)\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    # 记录参数\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # 训练模型\n",
    "    train_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            pred = model(batch_X)\n",
    "            loss = loss_function(pred, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        train_loss.append(epoch_loss / len(train_loader))\n",
    "\n",
    "        # 每10个 epoch 记录一次\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            test_loss = evaluate_model(model, test_loader, loss_function)\n",
    "            print('Epoch: {}, Train Loss: {:.10f}, Test Loss: {:.10f}'.format(epoch + 1, train_loss[-1], test_loss))\n",
    "            mlflow.log_metric(\"train_loss\", train_loss[-1], step=epoch)\n",
    "            mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
    "\n",
    "    # 在 MLflow 中记录模型和参数\n",
    "    mlflow.pytorch.log_model(model, \"models\")\n",
    "    mlflow.log_artifact(\"stock-price-prediction.py\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\py380\\lib\\site-packages\\nni\\runtime\\platform\\standalone.py:32: RuntimeWarning: \u001b[1m\u001b[31mRunning trial code without runtime. Please check the tutorial if you are new to NNI: \u001b[33mhttps://nni.readthedocs.io/en/stable/tutorials/hpo_quickstart_pytorch/main.html\u001b[0m\n",
      "  warnings.warn(warning_message, RuntimeWarning)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'hidden_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 更新模型参数\u001b[39;00m\n\u001b[0;32m     10\u001b[0m params \u001b[38;5;241m=\u001b[39m nni\u001b[38;5;241m.\u001b[39mget_next_parameter()\n\u001b[1;32m---> 11\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m num_layers \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m lr \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hidden_dim'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 定义模型\n",
    "num_epochs = 50\n",
    "model = LSTM(input_size=input_dim, hidden_size=hidden_dim, output_size=output_dim, num_layers=num_layers)\n",
    "# print(model)\n",
    "# 打印模型各层的参数尺寸\n",
    "\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "    \n",
    "loss_function = nn.MSELoss()  # 损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # 优化器\n",
    "\n",
    "\n",
    "\n",
    "train_loss = [] \n",
    "for epoch in range(num_epochs):\n",
    "    out = model(trainX)\n",
    "    loss = loss_function(out, trainY)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.append(loss.item())\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('Epoch: {}, Loss:{:.10f}'.format(epoch + 1, loss.item()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出NNI最终结果\n",
    "nni.report_final_result(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制loss函数图像\n",
    "plt.plot(train_loss)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2287c915b3db61027d50cb6eb72a988b8702097dccd2eb0ffd81756531a8644e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py380')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
